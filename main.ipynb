{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of functions\n",
    "----------------------------\n",
    "\n",
    "1. ridge_regression\n",
    "2. rank_cross_section_features\n",
    "3. random_fourier_features\n",
    "4. ranked_fourier_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(\n",
    "    signals: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    future_signals: np.ndarray,\n",
    "    shrinkage_list: np.ndarray,\n",
    "):\n",
    "    \"\"\"Smart Ridge Regression\"\"\"\n",
    "    t_ = signals.shape[0]\n",
    "    p_ = signals.shape[1]\n",
    "\n",
    "    matr = signals @ signals.T / t_\n",
    "\n",
    "    if p_ < t_:\n",
    "        # this is standard regression\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(np.dot(signals.T, signals) / t_)\n",
    "        means = signals.T @ labels.reshape(-1, 1) / t_\n",
    "        multiplied = eigenvectors.T @ means\n",
    "        intermed = np.concatenate(\n",
    "            [\n",
    "                (1 / (eigenvalues.reshape(-1, 1) + z)) * multiplied\n",
    "                for z in shrinkage_list\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        betas = eigenvectors @ intermed\n",
    "\n",
    "    else:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(matr)\n",
    "        means = labels.reshape(-1, 1) / t_\n",
    "        multiplied = eigenvectors.T @ means\n",
    "        intermed = np.concatenate(\n",
    "            [\n",
    "                (1 / (eigenvalues.reshape(-1, 1) + z)) * multiplied\n",
    "                for z in shrinkage_list\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        tmp = eigenvectors.T @ signals\n",
    "        betas = tmp.T @ intermed\n",
    "\n",
    "    predictions = future_signals @ betas\n",
    "    return betas, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_cross_section_features(X: pd.DataFrame, date_ids: np.ndarray):\n",
    "    \"\"\"Simple Cross-Section Ranking [-0.5, 0.5]\"\"\"\n",
    "    assert isinstance(X, pd.DataFrame)\n",
    "    X[\"date\"] = date_ids\n",
    "    X = X.groupby(\"date\").rank(pct=True, axis=0) - 0.5\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fourier_features(\n",
    "    x_train: pd.DataFrame, \n",
    "    x_test: pd.DataFrame, \n",
    "    number_features: int, \n",
    "    seed: int\n",
    "):\n",
    "    \"\"\"Clean Random Fourier Feature, see Rahimi 2007.\"\"\"\n",
    "    np.random.seed(seed=(seed+1*1e3))\n",
    "    weights = np.random.normal(loc=0, scale=1, size=[x_train.shape[1], number_features])\n",
    "\n",
    "    # np.__version__ == 1.26.4\n",
    "    # XXX np.arange(0.5, 1.1, step=0.1) bugged :(\n",
    "    gammas = np.random.choice(\n",
    "        [0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "        size=[x_train.train.shape[1], number_features], \n",
    "        replace=True\n",
    "    )\n",
    "    weights = weights * gammas\n",
    "    x_train_rff = pd.concat(\n",
    "        [getattr(np, activation)(x_train @ weights) for activation in [\"cos\", \"sin\"]]\n",
    "        \n",
    "    )\n",
    "    \n",
    "    x_test_rff = pd.concat(\n",
    "        [getattr(np, activation)(x_test @ weights) for activation in [\"cos\", \"sin\"]]\n",
    "    )\n",
    "\n",
    "    return x_train_rff, x_test_rff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_random_fourier_features(\n",
    "    x_train: pd.DataFrame, \n",
    "    x_test: pd.DataFrame, \n",
    "    number_features: int, \n",
    "    seed: int,\n",
    "    train_dates: np.ndarray\n",
    "):\n",
    "    \"\"\"Applies Ranking After RFF\"\"\"\n",
    "    x_train_rff, x_test_rff = random_fourier_features(\n",
    "        x_train=x_train,\n",
    "        x_test=x_test,\n",
    "        number_features=number_features,\n",
    "        seed=seed,\n",
    "    )\n",
    "    x_train_rff = rank_cross_section_features(\n",
    "        x_train_rff,\n",
    "        date_ids=train_dates\n",
    "    )\n",
    "    # XXX Monthly re-training\n",
    "    x_test_rff = x_test_rff.rank(pct=True, axis=0) - 0.5\n",
    "    return x_train_rff, x_test_rff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rolling_window_training(df: pd.DataFrame, rolling_window: int, long_only: bool) -> pd.DataFrame:\n",
    "    dates = df.date.unique().tolist()\n",
    "    dates.sort()\n",
    "    \n",
    "    start_window = 0\n",
    "    end_window = rolling_window\n",
    "    portfolio_returns = []\n",
    "    while start < len(dates):\n",
    "        start_time = time.monotonic()\n",
    " \n",
    "        train_dates = dates[start_window:end_window]\n",
    "        test_date = dates[end_window]\n",
    "\n",
    "        train = df[df.date.isin(train_dates)].copy()\n",
    "        test: pd.DataFrame = df[df.date == test_date].copy()\n",
    "\n",
    "        train.set_index(\"date\", inplace=True)\n",
    "        test.set_index(\"date\", inplace=True )\n",
    "        \n",
    "        y_train = train.pop(\"r_1\")\n",
    "        y_test = test.pop(\"r_1\")\n",
    "\n",
    "        train = train.multiply(y_train, axis=\"index\")\n",
    "        F_train = train.reset_index().groupby(\"date\").sum()\n",
    "        assert F_train.shape[0] == rolling_window\n",
    "        model = LinearRegression(fit_intercept=False, positive=long_only)\n",
    "        model.fit(F_train.values, np.ones(F_train.shape[0])) \n",
    "\n",
    "        prediction = test @ model.coef_\n",
    "        returns = prediction.values.reshape(1,-1) @ y_test\n",
    "        portfolio_returns.append({\n",
    "            \"date\": test_date,\n",
    "            \"return\": returns[0]\n",
    "        })\n",
    "        start_window += 1\n",
    "        end_window += 1\n",
    "        end_time = time.monotonic()\n",
    "        logging.info(f\"[{end_window}/{len(dates)}]\\tTraining Time:{end_time-start_time:.2f}s\\tPF Return:{returns[0]:3f}\")\n",
    "    return portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_features_rolling_window_training(\n",
    "        df: pd.DataFrame, \n",
    "        rolling_window: int,\n",
    "        number_features: int,\n",
    "        seed: int\n",
    ") -> pd.DataFrame:\n",
    "    dates = df.date.unique().tolist()\n",
    "    dates.sort()\n",
    "\n",
    "    start = rolling_window\n",
    "    i = 0\n",
    "    portfolio_returns = []\n",
    "    while start < len(dates):\n",
    "        \n",
    "        start_time = time.monotonic()\n",
    "        train_dates = dates[i:start]\n",
    "        test_date = dates[start]\n",
    "\n",
    "        train = df[df.date.isin(train_dates)].copy()\n",
    "        test: pd.DataFrame = df[df.date == test_date].copy()\n",
    "\n",
    "        y_train = train.pop(\"r_1\")\n",
    "        y_test = test.pop(\"r_1\")\n",
    "\n",
    "        train_dates = train.pop(\"date\")\n",
    "\n",
    "        x_train_rff, x_test_rff = ranked_random_fourier_features(\n",
    "            x_train=train,\n",
    "            x_test=test,\n",
    "            number_features=number_features, \n",
    "            seed=seed,\n",
    "            train_dates=train_dates\n",
    "        )\n",
    "\n",
    "        x_train_rff = x_train_rff.multiply(y_train, axis=\"index\")\n",
    "        x_train_rff.index = train_dates\n",
    "        F_train = train.reset_index().groupby(\"date\").sum()\n",
    "        assert F_train.shape[0] == rolling_window\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X=F_train, y=np.ones(F_train.shape[0]))\n",
    "        prediction = x_test_rff @ model.coef_\n",
    "        returns = prediction.values.reshape(1,-1) @ y_test\n",
    "        portfolio_returns.append({\n",
    "            \"date\": test_date,\n",
    "            \"return\": returns[0]\n",
    "        })\n",
    "        start += 1\n",
    "        i += 1\n",
    "        end_time = time.monotonic()\n",
    "        logging.info(f\"[{start}/{len(dates)}]\\tTraining Time:{end_time-start_time:.2f}s\\tPF Return:{returns[0]:.3f}\")\n",
    "    return portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirics\n",
    "Get the data from [Jensen, T. I., Kelly, B., & Pedersen, L. H. (2023).](https://jkpfactors.com/?country=usa&factor=all_factors&weighting=ew)<br>\n",
    "For simplicity, we will restrict the analysis to large and mega cap stocks only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          10006\n",
       "2          10102\n",
       "3          10145\n",
       "4          10153\n",
       "5          10161\n",
       "           ...  \n",
       "2486994    93356\n",
       "2486996    93369\n",
       "2487000    93374\n",
       "2487004    93427\n",
       "2487006    93436\n",
       "Name: id, Length: 671743, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jkp = pd.read_pickle(\"jkp_ranked_large_mega.pickle\")\n",
    "jkp.pop(\"size_grp\")\n",
    "jkp.pop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cowc_gr1a</th>\n",
       "      <th>oaccruals_at</th>\n",
       "      <th>oaccruals_ni</th>\n",
       "      <th>taccruals_at</th>\n",
       "      <th>taccruals_ni</th>\n",
       "      <th>debt_gr3</th>\n",
       "      <th>fnl_gr1a</th>\n",
       "      <th>ncol_gr1a</th>\n",
       "      <th>nfna_gr1a</th>\n",
       "      <th>...</th>\n",
       "      <th>div12m_me</th>\n",
       "      <th>ebitda_mev</th>\n",
       "      <th>eq_dur</th>\n",
       "      <th>eqnpo_12m</th>\n",
       "      <th>eqnpo_me</th>\n",
       "      <th>eqpo_me</th>\n",
       "      <th>ni_me</th>\n",
       "      <th>ocf_me</th>\n",
       "      <th>sale_me</th>\n",
       "      <th>r_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>671743</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "      <td>671743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1996-09-13 06:06:20.749185408</td>\n",
       "      <td>-0.019091</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.020176</td>\n",
       "      <td>0.014176</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.053547</td>\n",
       "      <td>-0.011736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.072738</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.093303</td>\n",
       "      <td>0.055811</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>-0.056205</td>\n",
       "      <td>0.006538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1963-01-31 00:00:00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.998298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1983-06-30 00:00:00</td>\n",
       "      <td>-0.191082</td>\n",
       "      <td>-0.177930</td>\n",
       "      <td>-0.222597</td>\n",
       "      <td>-0.192600</td>\n",
       "      <td>-0.225728</td>\n",
       "      <td>-0.156537</td>\n",
       "      <td>-0.212499</td>\n",
       "      <td>-0.168622</td>\n",
       "      <td>-0.231179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326073</td>\n",
       "      <td>-0.162813</td>\n",
       "      <td>-0.173141</td>\n",
       "      <td>-0.158307</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>-0.124022</td>\n",
       "      <td>-0.124103</td>\n",
       "      <td>-0.271667</td>\n",
       "      <td>-0.047461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1998-02-28 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.071793</td>\n",
       "      <td>-0.023029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.032006</td>\n",
       "      <td>0.124471</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>0.067191</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.043767</td>\n",
       "      <td>-0.074891</td>\n",
       "      <td>0.005307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010-07-31 00:00:00</td>\n",
       "      <td>0.139831</td>\n",
       "      <td>0.178554</td>\n",
       "      <td>0.175735</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>0.176757</td>\n",
       "      <td>0.195017</td>\n",
       "      <td>0.246354</td>\n",
       "      <td>0.290834</td>\n",
       "      <td>0.211918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265673</td>\n",
       "      <td>0.209884</td>\n",
       "      <td>0.222395</td>\n",
       "      <td>0.315263</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.284684</td>\n",
       "      <td>0.247790</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.143129</td>\n",
       "      <td>0.058897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-11-30 00:00:00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499656</td>\n",
       "      <td>2.997363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230908</td>\n",
       "      <td>0.238614</td>\n",
       "      <td>0.254723</td>\n",
       "      <td>0.245843</td>\n",
       "      <td>0.256605</td>\n",
       "      <td>0.241784</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>0.278295</td>\n",
       "      <td>0.264254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329512</td>\n",
       "      <td>0.236675</td>\n",
       "      <td>0.249492</td>\n",
       "      <td>0.282324</td>\n",
       "      <td>0.245779</td>\n",
       "      <td>0.229699</td>\n",
       "      <td>0.239658</td>\n",
       "      <td>0.234916</td>\n",
       "      <td>0.253979</td>\n",
       "      <td>0.106385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date      cowc_gr1a   oaccruals_at  \\\n",
       "count                         671743  671743.000000  671743.000000   \n",
       "mean   1996-09-13 06:06:20.749185408      -0.019091       0.002287   \n",
       "min              1963-01-31 00:00:00      -0.500000      -0.500000   \n",
       "25%              1983-06-30 00:00:00      -0.191082      -0.177930   \n",
       "50%              1998-02-28 00:00:00       0.000000       0.000000   \n",
       "75%              2010-07-31 00:00:00       0.139831       0.178554   \n",
       "max              2022-11-30 00:00:00       0.500000       0.500000   \n",
       "std                              NaN       0.230908       0.238614   \n",
       "\n",
       "        oaccruals_ni   taccruals_at   taccruals_ni       debt_gr3  \\\n",
       "count  671743.000000  671743.000000  671743.000000  671743.000000   \n",
       "mean       -0.019457      -0.002163      -0.020176       0.014176   \n",
       "min        -0.500000      -0.500000      -0.500000      -0.500000   \n",
       "25%        -0.222597      -0.192600      -0.225728      -0.156537   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.175735       0.187959       0.176757       0.195017   \n",
       "max         0.500000       0.500000       0.500000       0.500000   \n",
       "std         0.254723       0.245843       0.256605       0.241784   \n",
       "\n",
       "            fnl_gr1a      ncol_gr1a      nfna_gr1a  ...      div12m_me  \\\n",
       "count  671743.000000  671743.000000  671743.000000  ...  671743.000000   \n",
       "mean        0.020228       0.053547      -0.011736  ...      -0.006512   \n",
       "min        -0.500000      -0.500000      -0.500000  ...      -0.500000   \n",
       "25%        -0.212499      -0.168622      -0.231179  ...      -0.326073   \n",
       "50%         0.039233       0.071793      -0.023029  ...       0.049470   \n",
       "75%         0.246354       0.290834       0.211918  ...       0.265673   \n",
       "max         0.500000       0.500000       0.500000  ...       0.500000   \n",
       "std         0.269545       0.278295       0.264254  ...       0.329512   \n",
       "\n",
       "          ebitda_mev         eq_dur      eqnpo_12m       eqnpo_me  \\\n",
       "count  671743.000000  671743.000000  671743.000000  671743.000000   \n",
       "mean        0.023517       0.019616       0.072738       0.091148   \n",
       "min        -0.500000      -0.500000      -0.500000      -0.500000   \n",
       "25%        -0.162813      -0.173141      -0.158307      -0.036066   \n",
       "50%         0.013073       0.032006       0.124471       0.092892   \n",
       "75%         0.209884       0.222395       0.315263       0.298246   \n",
       "max         0.500000       0.500000       0.500000       0.500000   \n",
       "std         0.236675       0.249492       0.282324       0.245779   \n",
       "\n",
       "             eqpo_me          ni_me         ocf_me        sale_me  \\\n",
       "count  671743.000000  671743.000000  671743.000000  671743.000000   \n",
       "mean        0.093303       0.055811       0.050632      -0.056205   \n",
       "min        -0.500000      -0.500000      -0.500000      -0.500000   \n",
       "25%        -0.003119      -0.124022      -0.124103      -0.271667   \n",
       "50%         0.067191       0.059565       0.043767      -0.074891   \n",
       "75%         0.284684       0.247790       0.241699       0.143129   \n",
       "max         0.500000       0.500000       0.500000       0.499656   \n",
       "std         0.229699       0.239658       0.234916       0.253979   \n",
       "\n",
       "                 r_1  \n",
       "count  671743.000000  \n",
       "mean        0.006538  \n",
       "min        -0.998298  \n",
       "25%        -0.047461  \n",
       "50%         0.005307  \n",
       "75%         0.058897  \n",
       "max         2.997363  \n",
       "std         0.106385  \n",
       "\n",
       "[8 rows x 133 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jkp.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 60\n",
    "number_random_features = 2000\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[61/719]\tTraining Time:0.04s\tPF Return:0.886068\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m msrr_ols \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_rolling_window_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjkp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrolling_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrolling_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlong_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 23\u001b[0m, in \u001b[0;36mlinear_rolling_window_training\u001b[0;34m(df, rolling_window, long_only)\u001b[0m\n\u001b[1;32m     21\u001b[0m train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mmultiply(y_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m F_train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m F_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m rolling_window\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression(fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39mlong_only)\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(F_train\u001b[38;5;241m.\u001b[39mvalues, np\u001b[38;5;241m.\u001b[39mones(F_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])) \n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "msrr_ols = linear_rolling_window_training(df=jkp, rolling_window=rolling_window, long_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
